{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import pylab as py\n",
    "import gzip\n",
    "import math\n",
    "from scipy.optimize import fmin_bfgs, fmin_l_bfgs_b, fmin_cg\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import copy\n",
    "import bigfloat\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "import csv\n",
    "import hashlib\n",
    "from math import exp\n",
    "from math import log\n",
    "import warnings\n",
    "warnings.filterwarnings(\"error\")\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('categories.txt', 'rb') as content_file:\n",
    "    categories = content_file.read().split('\\n')\n",
    "#to make things faster i put the index where every category starts in a dictionary where the key are the product ids and \n",
    "#the values are the starting index of the category\n",
    "catindex = defaultdict(int)\n",
    "f = open('categories.txt','rb')\n",
    "for i,l in enumerate(f):\n",
    "    if len(l)-len(l.strip()) <=1:\n",
    "        catindex[l.strip()]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getYear(unix):\n",
    "    time = datetime.utcfromtimestamp(float(unix))\n",
    "    return time.strftime(\"%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#takes product id and returns category\n",
    "def getCategory(pid, categories, catdict, depth):\n",
    "    index = catdict[pid]\n",
    "    value = set()\n",
    "    j = index + 1\n",
    "    while len(categories[j])-len(categories[j].strip())>1:\n",
    "                ws = (categories[j].strip()).split(',')\n",
    "                break\n",
    "    return str((ws[:depth])[-1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "with open('500 core subset filtered.csv', 'rb') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        data.append((row['uid'], row['pid'], row['rating'], row['time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gethexdig(txt):\n",
    "    c = hashlib.md5(txt.encode())\n",
    "    return c.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top_genres(data):\n",
    "    gs= defaultdict(int)\n",
    "    for d in data:\n",
    "        cat = getCategory(d[1], categories, catindex, 3)\n",
    "        gs[cat]+=1\n",
    "    return set(sorted(gs.iteritems(), key= operator.itemgetter(1), reverse=True)[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gtop = get_top_genres(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print len(gtop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top_genres_hash_values(data):\n",
    "    gs = get_top_genres(data)\n",
    "#     print len(gs)\n",
    "    genres = set()\n",
    "    for g in gs:\n",
    "        genres.add(gethexdig(g[0])) \n",
    "    return genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "ghashed = get_top_genres_hash_values(data)\n",
    "print len(ghashed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "itemsuserrated = defaultdict(lambda: list())\n",
    "useritems = defaultdict(lambda: list())\n",
    "for d in data:\n",
    "    itemsuserrated[d[0]].append((d[1], d[3]))\n",
    "\n",
    "for u in itemsuserrated:\n",
    "    items = itemsuserrated[u]\n",
    "    isorted = sorted(items, key = lambda tup: tup[1])\n",
    "    itemsuserrated[u] = isorted\n",
    "    useritems[u] = [i[0] for i in isorted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "('A13G1TKIKHGV3F', '0060518499', '4.0', '1237075200')\n"
     ]
    }
   ],
   "source": [
    "print len(useritems)\n",
    "print data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ps = set()\n",
    "# for d in data:\n",
    "#     ps.add(d[1])\n",
    "# with open('550 core subset - with items not rated.csv', 'wb') as f:\n",
    "#     writer = csv.DictWriter(f, fieldnames=['user','irated','inrated'])\n",
    "#     writer.writeheader()\n",
    "#     for user in useritems:\n",
    "#         itemsrated = useritems[user] \n",
    "#         for i in itemsrated:\n",
    "#             notrated = np.random.choice(list(ps.difference(useritems[user])),size =10)\n",
    "#             for n in notrated:\n",
    "#                 writer.writerow({'user': user, 'irated': i, 'inrated': n})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print itemsuserrated['A2OJW07GQRNJUT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('500 core subset - with items not rated.csv', 'rb') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        data.append((row['user'], row['irated'], row['inrated']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def same_year(u1,u2):\n",
    "    d1= datetime.fromtimestamp(float(u1))\n",
    "    d2= datetime.fromtimestamp(float(u2))\n",
    "    delta = d1 - d2\n",
    "    return delta.days <=365 and delta.days >= 0\n",
    "\n",
    "def reviews_before_in_same_year(uid, pid):\n",
    "    pids = []\n",
    "    reviews = useritems[uid]\n",
    "    reviewswithtime = itemsuserrated[uid]\n",
    "    index = list(reviews).index(pid)\n",
    "    year = reviewswithtime[index][1]\n",
    "    for i in range(index):\n",
    "        if same_year(year, reviewswithtime[i][1]):\n",
    "            pids.append(reviewswithtime[i][0])\n",
    "    return pids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datag = []\n",
    "depth = 3\n",
    "dg = 'anything'\n",
    "for d in data:\n",
    "    cats = defaultdict(int)\n",
    "    index = list(useritems[d[0]]).index(d[1])\n",
    "    cgenre = getCategory(d[1],categories,catindex,depth)\n",
    "    if gethexdig(cgenre) not in ghashed:\n",
    "        cgenre = dg\n",
    "    ngenre = getCategory(d[2], categories,catindex, depth)\n",
    "    if gethexdig(ngenre) not in ghashed:\n",
    "        ngenre = dg\n",
    "    if not index==0:\n",
    "        pids = reviews_before_in_same_year(d[0], d[1])\n",
    "        for p in pids:\n",
    "            cat = getCategory(p, categories, catindex, depth)\n",
    "            if gethexdig(cat) not in ghashed :\n",
    "                cat = dg\n",
    "            cats[cat]+=1        \n",
    "    tup = (d + (cgenre,ngenre))\n",
    "    for c in cats:\n",
    "        tup = tup + (c, cats[c])\n",
    "    datag.append(tup)\n",
    "    \n",
    "k = 0\n",
    "genres = {}\n",
    "for g in gtop:\n",
    "    genres[g[0]] = k\n",
    "    k+=1\n",
    "genres[dg] = k\n",
    "len(genres)\n",
    "gside = len(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A2AYSFGUP5VTY3', '1856498050', '1401202209', 'anything', 'Graphic Novels', 'Humor', 2, 'Politics & Government', 2, 'Used & Rental Textbooks', 6, 'Fitness & Dieting', 1, 'Literary', 5, 'Music', 2, 'Education & Reference', 5, 'Religion & Spirituality', 1, 'History & Criticism', 2, 'Graphic Novels', 1, 'Ethnic & National', 2, 'Thriller & Suspense', 21, 'Biographies & Memoirs', 4, 'Economics', 1, 'Hobbies & Home', 2, 'Americas', 5, 'United States', 3, 'Leaders & Notable People', 3, 'Historical', 2, 'Classics', 10, 'anything', 29, 'People', 2, 'Arts & Literature', 4, 'Contemporary', 14, 'Books', 51, 'Literature & Fiction', 10)\n"
     ]
    }
   ],
   "source": [
    "print datag[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 51\n",
      "8241 8241\n",
      "('A2AYSFGUP5VTY3', '1856498050', '1401202209', 'anything', 'Graphic Novels', 'Humor', 2, 'Politics & Government', 2, 'Used & Rental Textbooks', 6, 'Fitness & Dieting', 1, 'Literary', 5, 'Music', 2, 'Education & Reference', 5, 'Religion & Spirituality', 1, 'History & Criticism', 2, 'Graphic Novels', 1, 'Ethnic & National', 2, 'Thriller & Suspense', 21, 'Biographies & Memoirs', 4, 'Economics', 1, 'Hobbies & Home', 2, 'Americas', 5, 'United States', 3, 'Leaders & Notable People', 3, 'Historical', 2, 'Classics', 10, 'anything', 29, 'People', 2, 'Arts & Literature', 4, 'Contemporary', 14, 'Books', 51, 'Literature & Fiction', 10)\n"
     ]
    }
   ],
   "source": [
    "print gside, len(genres)\n",
    "print len(datag), len(data)\n",
    "print datag[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ps = set()\n",
    "us = set()\n",
    "gs = set()\n",
    "for d in datag:\n",
    "    ps.add(d[1])\n",
    "    ps.add(d[2])\n",
    "    us.add(d[0])\n",
    "    for i in range(5,len(d), 2):\n",
    "        gs.add((d[i],d[3]))\n",
    "        gs.add((d[i], d[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "7976\n",
      "2601\n"
     ]
    }
   ],
   "source": [
    "print len(us)\n",
    "print len(ps)\n",
    "print len(gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users = {}\n",
    "products = {}\n",
    "i =0\n",
    "j=0\n",
    "for i,u in enumerate(us):\n",
    "    users[u] = i\n",
    "for j,p in enumerate(ps):\n",
    "    products[p] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # np.random.shuffle(datag)\n",
    "# dtest = set()\n",
    "# dvalid= set() #to choose best regualrization parameter and dimninsionality of factor vectors \n",
    "# dtestusers = defaultdict(int)\n",
    "# dvalidusers = defaultdict(int)\n",
    "# for r in datag:\n",
    "#     cr = len(itemsuserrated[r[0]])\n",
    "#     vc = int((cr * 30)/float(100))\n",
    "#     if dtestusers[r[0]]< vc:\n",
    "#         dtestusers[r[0]] +=1\n",
    "#         dtest.add(r)\n",
    "#     if r not in dtest and dvalidusers[r[0]]<vc:\n",
    "#         dvalidusers[r[0]]+=1\n",
    "#         dvalid.add(r)\n",
    "\n",
    "# dtrain = set()\n",
    "# for r in datag:\n",
    "#     if r not in dtest and r not in dvalid:\n",
    "#         dtrain.add(r)\n",
    "# dtrain = list(dtrain)\n",
    "# dtest = list(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4944 1648 1649 8241\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x60 = int((len(datag) * 60) / float(100))\n",
    "x20 = int((len(datag) * 20) / float(100))\n",
    "dtrain = datag[:x60]\n",
    "dvalid = datag[x60: x60+ x20]\n",
    "end =  x60+ x20\n",
    "dtest = datag[end:]\n",
    "print len(dtrain), len(dvalid), len(dtest), len(datag)\n",
    "print len(dtrain) + len(dvalid) + len(dtest) == len(datag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A2AYSFGUP5VTY3', '1856498050', '1401202209', 'anything', 'Graphic Novels', 'Humor', 2, 'Politics & Government', 2, 'Used & Rental Textbooks', 6, 'Fitness & Dieting', 1, 'Literary', 5, 'Music', 2, 'Education & Reference', 5, 'Religion & Spirituality', 1, 'History & Criticism', 2, 'Graphic Novels', 1, 'Ethnic & National', 2, 'Thriller & Suspense', 21, 'Biographies & Memoirs', 4, 'Economics', 1, 'Hobbies & Home', 2, 'Americas', 5, 'United States', 3, 'Leaders & Notable People', 3, 'Historical', 2, 'Classics', 10, 'anything', 29, 'People', 2, 'Arts & Literature', 4, 'Contemporary', 14, 'Books', 51, 'Literature & Fiction', 10)\n"
     ]
    }
   ],
   "source": [
    "print dtrain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#balanced error rate\n",
    "def BER(predictions, labels):\n",
    "    tp =0\n",
    "    fp=0\n",
    "    tn=0\n",
    "    fn=0\n",
    "    for i,l in enumerate(labels):\n",
    "        if l==1 and predictions[i]==l:\n",
    "            tp+=1\n",
    "        if l==0 and predictions[i]==l:\n",
    "            tn+=1\n",
    "        if l==1 and predictions[i]==0:\n",
    "            fn+=1\n",
    "        if l==0 and predictions[i]==1:\n",
    "            fp+=1\n",
    "    fpr = fp / float(fp+tn)\n",
    "    fnr = fn/ float(tp+fn)\n",
    "    return 0.5 * (fpr + fnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#function that takes a dataset and the optimized parameters and the diminsionality of the factors and returns the predictions for\n",
    "#this dataset using the parmaters\n",
    "def getPredictions_score(data, op,k):\n",
    "    predictions = []\n",
    "    betaio = op[:len(products)]\n",
    "    end = len(products)\n",
    "    bij = np.array(op[end: end+(gside**2)])\n",
    "    betaij = bij.reshape(gside, gside)\n",
    "    end = end + (gside**2)\n",
    "    gs = np.array(op[end:])\n",
    "    opp = gs.reshape(len(users)+len(products),k)\n",
    "    gammus = opp[:len(users),:]\n",
    "    gammis= opp[len(users):,:]\n",
    "    for d in data:\n",
    "        p1 = betaio[products[d[1]]] + gammus[users[d[0]]].dot(gammis[products[d[1]]])\n",
    "        p2 = betaio[products[d[2]]] + gammus[users[d[0]]].dot(gammis[products[d[2]]])\n",
    "        for i in range(5,len(d), 2):\n",
    "            p1 += betaij[genres[d[i]]][genres[d[3]]] * np.log10(d[i+1])\n",
    "            p2 += betaij[genres[d[i]]][genres[d[4]]]  * np.log10(d[i+1])\n",
    "        predictions.append(sigmoid(p1))\n",
    "        predictions.append(sigmoid(p2))\n",
    "    return np.array(predictions)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function that takes a dataset and the optimized parameters and the diminsionality of the factors and returns the predictions for\n",
    "#this dataset using the parmaters\n",
    "def getPredictions(data, op,k):\n",
    "#     print len(data)\n",
    "    predictions = []\n",
    "    betaio = op[:len(products)]\n",
    "    end = len(products)\n",
    "    bij = np.array(op[end: end+(gside**2)])\n",
    "    betaij = bij.reshape(gside, gside)\n",
    "    end = end + (gside**2)\n",
    "    gs = np.array(op[end:])\n",
    "    opp = gs.reshape(len(users)+len(products),k)\n",
    "    gammus = opp[:len(users),:]\n",
    "    gammis= opp[len(users):,:]\n",
    "    for d in data:\n",
    "        p1 = betaio[products[d[1]]] + gammus[users[d[0]]].dot(gammis[products[d[1]]])\n",
    "        p2 = betaio[products[d[2]]] + gammus[users[d[0]]].dot(gammis[products[d[2]]])\n",
    "        for i in range(5,len(d), 2):\n",
    "            p1 += betaij[genres[d[i]]][genres[d[3]]]  * np.log10(d[i+1])\n",
    "            p2 += betaij[genres[d[i]]][genres[d[4]]]  * np.log10(d[i+1])\n",
    "        predictions.append(sigmoid(p1)>0.5)\n",
    "        predictions.append(sigmoid(p2)>0.5)\n",
    "    return np.array(predictions)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A2AYSFGUP5VTY3', '1856498050', '1401202209', 'anything', 'Graphic Novels', 'Humor', 2, 'Politics & Government', 2, 'Used & Rental Textbooks', 6, 'Fitness & Dieting', 1, 'Literary', 5, 'Music', 2, 'Education & Reference', 5, 'Religion & Spirituality', 1, 'History & Criticism', 2, 'Graphic Novels', 1, 'Ethnic & National', 2, 'Thriller & Suspense', 21, 'Biographies & Memoirs', 4, 'Economics', 1, 'Hobbies & Home', 2, 'Americas', 5, 'United States', 3, 'Leaders & Notable People', 3, 'Historical', 2, 'Classics', 10, 'anything', 29, 'People', 2, 'Arts & Literature', 4, 'Contemporary', 14, 'Books', 51, 'Literature & Fiction', 10)\n"
     ]
    }
   ],
   "source": [
    "print dtrain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def AUC(data, op, k):\n",
    "    count = 0\n",
    "    predictions = getPredictions_score(data, op,k)\n",
    "    for i in range(0, len(predictions), 2):\n",
    "        if predictions[i] > predictions[i+1]:\n",
    "            count +=1\n",
    "#     print count, len(data)\n",
    "    return count / float(len(data))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#takes the data and returns the true labels for this dataset\n",
    "def getLabels(data):\n",
    "    labels = []\n",
    "    for d in data:\n",
    "        labels.append(1)\n",
    "        labels.append(0)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    try:\n",
    "        f = sc.special.expit(z)\n",
    "    except RuntimeWarning:\n",
    "        f = 1/float(1 + bigfloat.exp(-z, bigfloat.precision(100)))\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uintrain = set()\n",
    "pintrain = set()\n",
    "gintrain = set()\n",
    "for d in dtrain:\n",
    "    pintrain.add(d[1])\n",
    "    pintrain.add(d[2])\n",
    "    uintrain.add(d[0])\n",
    "    for i in xrange(5,len(d), 2):\n",
    "        gintrain.add((d[i], d[3]))\n",
    "        gintrain.add((d[i], d[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_cost(initial,lam1, lam2, k, dataset):\n",
    "    betai = np.array(initial[:len(products)])\n",
    "    end = len(products)\n",
    "    bij = np.array(initial[end: end+(gside**2)])\n",
    "    betaij = bij.reshape(gside, gside)\n",
    "    end = end + (gside**2)\n",
    "    gammas = np.array(initial[end:])\n",
    "    gss = gammas.reshape(len(users)+len(products), k)\n",
    "    gammau = gss[:len(users),:]\n",
    "    gammai = gss[len(users):, :]\n",
    "    J = 0\n",
    "    for d in dataset: \n",
    "        term = (betai[products[d[1]]] + gammau[users[d[0]]].dot(gammai[products[d[1]]])) - (betai[products[d[2]]] + gammau[users[d[0]]].dot(gammai[products[d[2]]]))\n",
    "        for i in range(5,len(d), 2):\n",
    "            term += (betaij[genres[d[i]]][genres[d[3]]] - betaij[genres[d[i]]][genres[d[4]]])  * np.log10(d[i+1])\n",
    "\n",
    "        J+= np.logaddexp(0, -term)\n",
    "    for u in us:\n",
    "        J += lam1 * np.sum(np.square(gammau[users[u]]))\n",
    "    for p in ps:\n",
    "        J+= lam1 * ( np.square(betai[products[p]]) + np.sum(np.square(gammai[products[p]])))\n",
    "    for g in gs:\n",
    "        J+= lam2 * np.square(betaij[genres[g[0]]][genres[g[1]]])\n",
    "\n",
    "    g = gradient(betai, betaij, gammau,gammai,lam1,lam2, k, dataset)\n",
    "#     print J\n",
    "    return J,g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gradient(betai,betaij, gammau,gammai, lam1, lam2, k, dataset):\n",
    "    gbi = np.zeros(len(products))\n",
    "    ggu = np.zeros((len(users),k))\n",
    "    ggi = np.zeros((len(products),k))\n",
    "    ggij = np.zeros((gside,gside))\n",
    "    \n",
    "    for d in dataset:\n",
    "        term = (betai[products[d[1]]] + gammau[users[d[0]]].dot(gammai[products[d[1]]])) - (betai[products[d[2]]] + gammau[users[d[0]]].dot(gammai[products[d[2]]]))\n",
    "        \n",
    "        for i in range(5,len(d), 2):\n",
    "            term += (betaij[genres[d[i]]][genres[d[3]]] - betaij[genres[d[i]]][genres[d[4]]])  * np.log10(d[i+1])\n",
    "        try:\n",
    "            f = np.exp(-term) * sigmoid(term)\n",
    "        except RuntimeWarning:\n",
    "            f = float((bigfloat.exp(-term, bigfloat.precision(100))) * (sigmoid(term)))\n",
    "        ggu[users[d[0]]] += (gammai[products[d[2]]] - gammai[products[d[1]]]) * f\n",
    "        ggi[products[d[1]]]  += (-gammau[users[d[0]]]) * f\n",
    "        ggi[products[d[2]]] += gammau[users[d[0]]] * f\n",
    "        gbi[products[d[1]]] += (-1) *f\n",
    "        gbi[products[d[2]]] += f\n",
    "        for i in range(5,len(d), 2):\n",
    "            ggij[genres[d[i]]][genres[d[3]]] += (-1) * f  * np.log10(d[i+1])\n",
    "            ggij[genres[d[i]]][genres[d[4]]] += f  * np.log10(d[i+1])\n",
    "\n",
    "    for u in us:\n",
    "        ggu[users[u]] += 2 * lam1 * gammau[users[u]]\n",
    "    for p in ps:\n",
    "        gbi[products[p]] += 2 * lam1 * betai[products[p]]\n",
    "        ggi[products[p]] += 2 * lam1 * gammai[products[p]]\n",
    "    for g in gs:\n",
    "        ggij[genres[g[0]]][genres[g[1]]] += 2 * lam2 * betaij[genres[g[0]]][genres[g[1]]]\n",
    "    \n",
    "    l = list(gbi) + list(ggij.flatten()) + list(ggu.flatten()) + list(ggi.flatten())\n",
    "\n",
    "    return np.array(l)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost(initial, k, dataset):\n",
    "    betai = np.array(initial[:len(products)])\n",
    "    end = len(products)\n",
    "    bij = np.array(initial[end: end+(gside**2)])\n",
    "    betaij = bij.reshape(gside, gside)\n",
    "    end = end + (gside**2)\n",
    "    gammas = np.array(initial[end:])\n",
    "    gss = gammas.reshape(len(users)+len(products), k)\n",
    "    gammau = gss[:len(users),:]\n",
    "    gammai = gss[len(users):, :]\n",
    "    J = 0\n",
    "    for d in dataset: \n",
    "        term = (betai[products[d[1]]] +gammau[users[d[0]]].dot(gammai[products[d[1]]]))-(betai[products[d[2]]] +gammau[users[d[0]]].dot(gammai[products[d[2]]]))\n",
    "        for i in range(5,len(d), 2):\n",
    "            term += (betaij[genres[d[i]]][genres[d[3]]] - betaij[genres[d[i]]][genres[d[4]]])  * np.log10(d[i+1])\n",
    "\n",
    "        J+= np.logaddexp(0, -term)\n",
    "   \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ConvergedException(Exception):\n",
    "    pass\n",
    "def check(xk):\n",
    "    global result\n",
    "    global presult\n",
    "    global maxauc\n",
    "    global count\n",
    "    global mincost\n",
    "    global nit\n",
    "    \n",
    "    nit+=1\n",
    "\n",
    "    ccost = cost(xk, k, dvalid)\n",
    "    \n",
    "    if ccost> mincost:\n",
    "        if nit >=100:\n",
    "            count +=1\n",
    "            if count == 20:\n",
    "                print 'here'\n",
    "                result[:] = presult\n",
    "                raise ConvergedException()\n",
    "                return\n",
    "\n",
    "    else:\n",
    "        mincost = ccost\n",
    "        presult[:] = xk\n",
    "        count = 0\n",
    "#     print ccost, mincost\n",
    "\n",
    "#     fpr, tpr, _ = roc_curve(getLabels(dvalid),getPredictions_score(dvalid, xk, k))\n",
    "#     cauc = auc(fpr,tpr)\n",
    "#     if cauc < maxauc:\n",
    "#         count +=1\n",
    "#         if count == 10:\n",
    "#             print 'here'\n",
    "#             result = presult\n",
    "#             raise ConvergedException()\n",
    "#             return\n",
    "#     else: \n",
    "#         maxauc = cauc\n",
    "#         count = 0\n",
    "#         presult[:] = xk\n",
    "#     print cauc, maxauc, presult[0]\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 10\n",
    "betai = np.random.normal(0,0.1, len(products))\n",
    "betaij = np.random.normal(0,0.1, (gside,gside))\n",
    "gammai = np.random.normal(0, 0.1, (len(products), k))\n",
    "gammau = np.random.normal(0, 0.1, (len(users), k))\n",
    "for u in users:\n",
    "    if u not in uintrain:\n",
    "        gammau[users[u]] = 0\n",
    "for p in products:\n",
    "    if p not in pintrain:\n",
    "        gammai[products[p]]=0\n",
    "        betai[products[p]]=0\n",
    "for g in gs:\n",
    "    if g not in gintrain:\n",
    "        betaij[genres[g[0]]][genres[g[1]]] = 0\n",
    "initial = list(betai) + list(betaij.flatten()) + list(gammau.flatten()) + list(gammai.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvergedException(Exception):\n",
    "    pass\n",
    "def check_updated(xk):\n",
    "    global result\n",
    "    global presult\n",
    "    global maxauc\n",
    "    global count\n",
    "    global mincost\n",
    "    global nit\n",
    "    \n",
    "    nit+=1\n",
    "\n",
    "#     ccost = cost(xk, k, dvalid)\n",
    "    \n",
    "#     if ccost> mincost:\n",
    "#         count +=1\n",
    "#         if count == 30:\n",
    "#             print 'here'\n",
    "#             result[:] = presult\n",
    "#             raise ConvergedException()\n",
    "#             return\n",
    "\n",
    "#     else:\n",
    "#         mincost = ccost\n",
    "#         presult[:] = xk\n",
    "#         count = 0\n",
    "#     fpr, tpr, _ = roc_curve(getLabels(dvalid),getPredictions_score(dvalid, xk, k))\n",
    "    cauc = AUC(dvalid, xk, k)\n",
    "    if cauc < maxauc:\n",
    "        count +=1\n",
    "        if count == 30:\n",
    "            print 'here'\n",
    "            result[:] = presult\n",
    "            raise ConvergedException()\n",
    "    else: \n",
    "        maxauc = cauc\n",
    "        count = 0\n",
    "        presult[:] = xk\n",
    "#     print maxauc\n",
    "#     , AUC(dtest, xk, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class ConvergedException(Exception):\n",
    "#     pass\n",
    "# def check_updated(xk):\n",
    "#     global result\n",
    "#     global presult\n",
    "#     global maxauc\n",
    "#     global count\n",
    "#     global mincost\n",
    "#     global nit\n",
    "    \n",
    "#     nit+=1\n",
    "\n",
    "# #     ccost = cost(xk, k, dvalid)\n",
    "    \n",
    "# #     if ccost> mincost:\n",
    "# #         count +=1\n",
    "# #         if count == 30:\n",
    "# #             print 'here'\n",
    "# #             result[:] = presult\n",
    "# #             raise ConvergedException()\n",
    "# #             return\n",
    "\n",
    "# #     else:\n",
    "# #         mincost = ccost\n",
    "# #         presult[:] = xk\n",
    "# #         count = 0\n",
    "# #     fpr, tpr, _ = roc_curve(getLabels(dvalid),getPredictions_score(dvalid, xk, k))\n",
    "#     if count % 20 == 0:\n",
    "#         cauc = AUC(dvalid, xk, k)\n",
    "#         if cauc < maxauc:\n",
    "# #             count +=1\n",
    "# #             if count == 30:\n",
    "#             print 'here'\n",
    "#             result[:] = presult\n",
    "#             raise ConvergedException()\n",
    "#         else: \n",
    "#             maxauc = cauc\n",
    "#             count = 0\n",
    "#             presult[:] = xk\n",
    "#         print cauc\n",
    "#     count +=1\n",
    "\n",
    "# #     print maxauc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "converged after :95\n",
      "0.01 -> 0 : 1288.79687203 1153.0717153 0.750606796117 0.770163735597\n",
      "here\n",
      "converged after :98\n",
      "0.01 -> 1e-05 : 1310.26090245 1173.11109058 0.75182038835 0.770163735597\n",
      "here\n",
      "converged after :85\n",
      "0.01 -> 0.0001 : 1337.72178958 1186.15308135 0.751213592233 0.768950879321\n",
      "here\n",
      "converged after :110\n",
      "0.01 -> 0.001 : 1046.57081058 954.325940433 0.762742718447 0.770770163736\n",
      "here\n",
      "converged after :220\n",
      "0.01 -> 0.01 : 788.873293958 750.997506183 0.783373786408 0.773802304427\n",
      "here\n",
      "converged after :66\n",
      "0.01 -> 0.1 : 1127.82047751 1051.65430483 0.726334951456 0.73074590661\n",
      "here\n",
      "converged after :44\n",
      "0.01 -> 1 : 832.10832928 799.440667064 0.718446601942 0.732565191025\n",
      "here\n",
      "converged after :43\n",
      "0.01 -> 10 : 834.734553518 817.455501436 0.714805825243 0.733171619163\n",
      "here\n",
      "converged after :40\n",
      "0.01 -> 100 : 966.658870811 962.098238393 0.68567961165 0.701637355973\n",
      "here\n",
      "converged after :37\n",
      "0.01 -> 1000 : 1092.87593565 1091.96075978 0.619538834951 0.618556701031\n",
      "here\n",
      "converged after :34\n",
      "0.01 -> 10000 : 1136.42194357 1136.430551 0.542475728155 0.554881746513\n"
     ]
    }
   ],
   "source": [
    "lams1 = [0.01]\n",
    "lams2 = [0, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "for l1 in lams1:\n",
    "    for l2 in lams2: \n",
    "        count = 0\n",
    "        presult = []\n",
    "        result = []\n",
    "        params = []\n",
    "        maxauc = 0\n",
    "        mincost = 100000000000000\n",
    "        nit = 0\n",
    "        try:\n",
    "            params, c,d = fmin_l_bfgs_b(compute_cost, x0=initial,args=(l1, l2, k, dtrain, ), disp = 0, callback=check_updated)\n",
    "            params = presult\n",
    "            print 'normal'\n",
    "        except ConvergedException:\n",
    "            params = result\n",
    "        print 'converged after :' + str(nit)\n",
    "        print str(l1) + ' -> '+ str(l2) + ' : '+ str(cost(params, k, dvalid)) + ' ' +  str(cost(params, k , dtest)) + ' ' + str(AUC(dvalid, params, k)) + ' ' + str(AUC(dtest, params, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "converged after :180\n",
      "0.001 -> 0 : 57.5285679506 59.651989062 0.999450750641 0.999221896741\n",
      "here\n",
      "converged after :184\n",
      "0.001 -> 1e-05 : 39.4175757403 40.6297451519 0.99967960454 0.999542292201\n",
      "here\n",
      "converged after :252\n",
      "0.001 -> 0.0001 : 18.0247646876 19.0062402377 0.99986268766 0.99986268766\n",
      "here\n",
      "converged after :212\n",
      "0.001 -> 0.001 : 14.0539212384 16.6328567549 0.99995422922 0.99986268766\n",
      "here\n",
      "converged after :314\n",
      "0.001 -> 0.01 : 12.5329634224 12.2363288325 1.0 0.99995422922\n",
      "here\n",
      "converged after :125\n",
      "0.001 -> 0.1 : 24.4118649628 31.3441962585 0.99990845844 0.99972537532\n",
      "here\n",
      "converged after :225\n",
      "0.001 -> 1 : 25.8060611734 31.4512118142 0.99986268766 0.99967960454\n",
      "here\n",
      "converged after :322\n",
      "0.001 -> 10 : 33.5252134667 45.6853829185 0.99986268766 0.999633833761\n",
      "here\n",
      "converged after :1019\n",
      "0.001 -> 100 : 25.2687995218 29.6938471607 0.99990845844 0.9997711461\n",
      "here\n",
      "converged after :1040\n",
      "0.001 -> 1000 : 267.851757768 218.680476774 0.998581105822 0.998672647382\n",
      "here\n",
      "converged after :216\n",
      "0.001 -> 10000 : 1482.8406358 1442.6935658 0.983019040644 0.983110582204\n"
     ]
    }
   ],
   "source": [
    "lams1 = [0.001]\n",
    "lams2 = [0, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "for l1 in lams1:\n",
    "    for l2 in lams2: \n",
    "        count = 0\n",
    "        presult = []\n",
    "        result = []\n",
    "        params = []\n",
    "        maxauc = 0\n",
    "        mincost = 100000000000000\n",
    "        nit = 0\n",
    "        try:\n",
    "            params, c,d = fmin_l_bfgs_b(compute_cost, x0=initial,args=(l1, l2, k, dtrain, ), disp = 0, callback=check_updated)\n",
    "            params = presult\n",
    "            print 'normal'\n",
    "        except ConvergedException:\n",
    "            params = result\n",
    "        print 'converged after :' + str(nit)\n",
    "        print str(l1) + ' -> '+ str(l2) + ' : '+ str(cost(params, k, dvalid)) + ' ' +  str(cost(params, k , dtest)) + ' ' + str(AUC(dvalid, params, k)) + ' ' + str(AUC(dtest, params, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "converged after :145\n",
      "0.001 -> 0 : 0.999179735585\n",
      "here\n",
      "converged after :203\n",
      "0.001 -> 1e-05 : 0.99960204163\n",
      "here\n",
      "converged after :215\n",
      "0.001 -> 0.0001 : 0.999903883038\n",
      "here\n",
      "converged after :191\n",
      "0.001 -> 0.001 : 0.999884449102\n",
      "here\n",
      "converged after :180\n",
      "0.001 -> 0.01 : 0.999875461705\n",
      "here\n",
      "converged after :186\n",
      "0.001 -> 0.1 : 0.999877538862\n",
      "here\n",
      "converged after :236\n",
      "0.001 -> 1 : 0.999863228161\n",
      "here\n",
      "converged after :623\n",
      "0.001 -> 10 : 0.999884632411\n",
      "here\n",
      "converged after :119\n",
      "0.001 -> 100 : 0.993877891076\n",
      "here\n",
      "converged after :264\n",
      "0.001 -> 1000 : 0.991662602506\n",
      "here\n",
      "converged after :279\n",
      "0.001 -> 10000 : 0.976040141602\n"
     ]
    }
   ],
   "source": [
    "# lams = [0, 0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "lams1 = [0.001]\n",
    "lams2 = [0, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "with open('Binary baseline - Pairwise genre bias terms (Adjacent) 400 core.csv', 'wb') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['lambda1', 'lambda2','k','value'])\n",
    "    writer.writeheader()\n",
    "    for l1 in lams1:\n",
    "         for l2 in lams2:\n",
    "            count = 0\n",
    "            nit = 0\n",
    "            presult = []\n",
    "            result = []\n",
    "            maxauc = 0\n",
    "            params = []\n",
    "            mincost = 100000000\n",
    "            try:\n",
    "                params, c,d = fmin_l_bfgs_b(compute_cost, x0=initial,args=(l1, l2, k, dtrain, ), disp = 0, callback = check)\n",
    "                params = presult\n",
    "            except ConvergedException:\n",
    "                params = result\n",
    "            print 'converged after :' + str(nit)\n",
    "            fpr, tpr, _ = roc_curve(getLabels(dvalid),getPredictions_score(dvalid, params, k))\n",
    "            print str(l1) + ' -> ' + str(l2) + ' : ' +  str(auc(fpr, tpr))\n",
    "\n",
    "#             print str(l1) + ' -> ' + str(l2) + ' : ' +  str(cost(params, k, dvalid))\n",
    "            for i, v in enumerate(params):\n",
    "                writer.writerow({'lambda1': l1, 'lambda2': l2, 'k': k, 'value': v}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116732\n"
     ]
    }
   ],
   "source": [
    "print len(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = defaultdict(lambda:defaultdict(list))\n",
    "with open('Binary baseline - Pairwise genre bias terms (Adjacent) 400 core.csv', 'rb') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        params[(float(row['lambda1']), float(row['lambda2']))][int(row['k'])].append(float(row['value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print len(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#takes dictionary of parameters in the form of  {lambda value: k value: [parameters]} and choose the lambda value and k value that\n",
    "#minimize the balanced error rate\n",
    "def chooseBestParams(data, params):\n",
    "    minError = 1000000000\n",
    "    maxauc = 0\n",
    "    labs = getLabels(data)\n",
    "    for l in params:\n",
    "        for k in params[l]:\n",
    "#             fpr, tpr, _ = roc_curve(getLabels(dvalid),getPredictions_score(dvalid, params[l][k], k))\n",
    "#             cauc = auc(fpr,tpr)\n",
    "#             if cauc > maxauc:\n",
    "#                 maxauc = cauc\n",
    "#                 minlam = l\n",
    "#                 op = params[l][k]\n",
    "\n",
    "\n",
    "            e = cost(params[l][k], k, data)\n",
    "#             print l, e\n",
    "#             print l, k , e\n",
    "            if e < minError:\n",
    "                minError = e\n",
    "                minlam = l\n",
    "                op = params[l][k]\n",
    "    return minlam, op, minError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.001, 0.001) 9.93178579845\n"
     ]
    }
   ],
   "source": [
    "minlam, op, e = chooseBestParams(dvalid, params)\n",
    "print minlam,e "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.5266741589\n"
     ]
    }
   ],
   "source": [
    "print cost(op, k, dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.743070239412\n"
     ]
    }
   ],
   "source": [
    "print cost(op, k, dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999900908189\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, _ = roc_curve(getLabels(dtest),getPredictions_score(dtest, op, k))\n",
    "roc_auc = auc(fpr,tpr)\n",
    "print roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999999985335\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, _ = roc_curve(getLabels(dtrain),getPredictions_score(dtrain, op, k))\n",
    "roc_auc = auc(fpr,tpr)\n",
    "print roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.156993775174\n"
     ]
    }
   ],
   "source": [
    "preds = getPredictions(dtest, op, k)\n",
    "labels = getLabels(dtest)\n",
    "print BER(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_curve, auc\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure()\n",
    "# plt.plot(fpr, tpr, label='ROC curve (area = %0.5f)' % roc_auc)\n",
    "# plt.plot([0, 1], [0, 1], 'k--')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('ROC Curve Adjacent')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# labs = getLabels(dtest)\n",
    "# preds = getPredictions(dtest, op,mink)\n",
    "# e = BER(preds,labs)\n",
    "# print e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mink = 1\n",
    "# minlam = 10\n",
    "# betai = np.random.normal(0,0.1, len(products))\n",
    "# betaij = np.random.normal(0,0.1, (gside, gside))\n",
    "# gammai = np.random.normal(0, 0.01, (len(products), mink))\n",
    "# gammau = np.random.normal(0, 0.01, (len(users), mink))\n",
    "# initial = list(betai.flatten())+ list(betaij.flatten()) + list(gammau.flatten()) + list(gammai.flatten())\n",
    "# grad = gradient(betai,betaij, gammau, gammai, minlam,mink, dtrain[:1])\n",
    "# numgrad = computeNumericalGradient(initial,grad, minlam, mink, dtrain[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost1(initial,lam,k, dataset):\n",
    "    betai = np.array(initial[:len(products)])\n",
    "    end = len(products)\n",
    "    bij = np.array(initial[end: end+(gside**2)])\n",
    "    betaij = bij.reshape(gside, gside)\n",
    "    end = end + (gside**2)\n",
    "    gammas = np.array(initial[end:])\n",
    "    gss = gammas.reshape(len(users)+len(products), k)\n",
    "    gammau = gss[:len(users),:]\n",
    "    gammai = gss[len(users):, :]\n",
    "    J = 0\n",
    "    for d in dataset: \n",
    "        term = (betai[products[d[1]]] +gammau[users[d[0]]].dot(gammai[products[d[1]]]))-(betai[products[d[2]]] +gammau[users[d[0]]].dot(gammai[products[d[2]]]))\n",
    "        for i in range(5,len(d)):\n",
    "            term += betaij[genres[d[i]]][genres[d[3]]] - betaij[genres[d[i]]][genres[d[4]]]\n",
    "\n",
    "        J+= np.logaddexp(0, -term)\n",
    "    for u in us:\n",
    "        J += lam * np.sum(np.square(gammau[users[u]]))\n",
    "    for p in ps:\n",
    "        J+= lam * ( np.square(betai[products[p]]) + np.sum(np.square(gammai[products[p]])))\n",
    "    for g in gs:\n",
    "        J+= lam * np.square(betaij[genres[g[0]]][genres[g[1]]])\n",
    "\n",
    "#     print J\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gradient1(initial, lam,k, dataset):\n",
    "    betai = np.array(initial[:len(products)])\n",
    "    end = len(products)\n",
    "    bij = np.array(initial[end: end+(gside**2)])\n",
    "    betaij = bij.reshape(gside, gside)\n",
    "    end = end + (gside**2)\n",
    "    gammas = np.array(initial[end:])\n",
    "    gss = gammas.reshape(len(users)+len(products), k)\n",
    "    gammau = gss[:len(users),:]\n",
    "    gammai = gss[len(users):, :]\n",
    "    gbi = np.zeros(len(products))\n",
    "    ggu = np.zeros((len(users),k))\n",
    "    ggi = np.zeros((len(products),k))\n",
    "    ggij = np.zeros((gside,gside))\n",
    "    \n",
    "    for d in dataset:\n",
    "        term = (betai[products[d[1]]] + gammau[users[d[0]]].dot(gammai[products[d[1]]])) -(betai[products[d[2]]] + gammau[users[d[0]]].dot(gammai[products[d[2]]]))    \n",
    "        \n",
    "        for i in range(5,len(d)):\n",
    "            term += betaij[genres[d[i]]][genres[d[3]]] - betaij[genres[d[i]]][genres[d[4]]]\n",
    "        try:\n",
    "            f = np.exp(-term) * sigmoid(term)\n",
    "        except RuntimeWarning:\n",
    "            f = float((bigfloat.exp(-term, bigfloat.precision(100))) * (sigmoid(term)))\n",
    "        ggu[users[d[0]]] += (gammai[products[d[2]]] - gammai[products[d[1]]]) * f\n",
    "        ggi[products[d[1]]]  += (-gammau[users[d[0]]]) * f\n",
    "        ggi[products[d[2]]] += gammau[users[d[0]]] * f\n",
    "        gbi[products[d[1]]] += (-1) *f\n",
    "        gbi[products[d[2]]] += f\n",
    "        for i in range(5,len(d)):\n",
    "            ggij[genres[d[i]]][genres[d[3]]] += (-1) * f\n",
    "            ggij[genres[d[i]]][genres[d[4]]] += f\n",
    "\n",
    "    for u in us:\n",
    "        ggu[users[u]] += 2 * lam * gammau[users[u]]\n",
    "    for p in ps:\n",
    "        gbi[products[p]] += 2 * lam * betai[products[p]]\n",
    "        ggi[products[p]] += 2 * lam * gammai[products[p]]\n",
    "    for g in gs:\n",
    "        ggij[genres[g[0]]][genres[g[1]]] += 2 * lam * betaij[genres[g[0]]][genres[g[1]]]\n",
    "    \n",
    "    l = list(gbi) + list(ggij.flatten()) + list(ggu.flatten()) + list(ggi.flatten())\n",
    "\n",
    "    return np.array(l)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeNumericalGradient(params,grad, l1, l2, k, data):\n",
    "    e = 1e-4\n",
    "    numgrads = np.zeros(len(params))\n",
    "    pp = np.zeros(len(params))\n",
    "    for i,p in enumerate(params):\n",
    "        pp[i] = e\n",
    "        loss1, _ = compute_cost(params-pp, l1, l2, k,data)\n",
    "        loss2, _ = compute_cost(params+pp, l1,l2,k, data)\n",
    "#         print loss1, loss2\n",
    "        numgrads[i] = (loss2 - loss1) / float(2*e)\n",
    "        pp[i] = 0\n",
    "        print round(numgrads[i], 3), round(grad[i], 3)\n",
    "#         print abs(numgrads[i]-grad[i])\n",
    "    return numgrads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# _,g = compute_cost(initial, 0.1, 1, 10, dtrain[:1])\n",
    "# numgrad = computeNumericalGradient(initial,g ,0.1, 1 , 10 , dtrain[:1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diff = np.linalg.norm(numgrad-g)/np.linalg.norm(numgrad+g);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print diff < 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2923313768e-10\n"
     ]
    }
   ],
   "source": [
    "print diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print compute_cost(params, 0, 10, dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
